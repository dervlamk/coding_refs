{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "909be85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import dask\n",
    "import intake\n",
    "import collections\n",
    "import fsspec\n",
    "import seaborn as sns\n",
    "from xmip.preprocessing import combined_preprocessing\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.rcParams['figure.figsize'] = 12, 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "825f1bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_lat_lon_names(ds):\n",
    "    for lat_name in ['y', 'latitude', 'nav_lat']:\n",
    "        if (lat_name in ds.coords) and ('lat' not in ds.coords):\n",
    "            ds=ds.rename({lat_name: 'lat'})\n",
    "        else:\n",
    "            ds=ds\n",
    "    for lon_name in ['x', 'longitude', 'nav_lon']:\n",
    "        if (lon_name in ds.coords) and ('lon' not in ds.coords):\n",
    "            ds = ds.rename({lon_name: 'lon'})\n",
    "        else:\n",
    "            ds=ds\n",
    "    return ds\n",
    "\n",
    "\n",
    "def drop_all_bounds(ds):\n",
    "    drop_vars = [vname for vname in ds.coords\n",
    "                 if ( (('_bounds') in vname) or \n",
    "                     (('_bnds') in vname) )]\n",
    "    return ds.drop(drop_vars)\n",
    "\n",
    "def add_source_id_coord(ds):\n",
    "    ds = ds.assign_coords(source_id=ds.attrs.get('source_id'))\n",
    "    return ds\n",
    "\n",
    "def annual_climatology(ds):\n",
    "    # First calculate the monthly climatologies\n",
    "    ds_avg = ds.groupby('time.month').mean(dim='time', keep_attrs=True).mean(dim='month', keep_attrs=True)\n",
    "    return(ds_avg)\n",
    "\n",
    "def monthly_climatology(ds):\n",
    "    # First calculate the monthly climatologies\n",
    "    ds_mon = ds.groupby('time.month').mean(dim='time', keep_attrs=True)\n",
    "    return(ds_mon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae1f7de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Open up the PANGEO-CMIP6 repository\n",
    "url='https://storage.googleapis.com/cmip6/pangeo-cmip6.json'\n",
    "cmip6=intake.open_esm_datastore(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c517f6",
   "metadata": {},
   "source": [
    "Limiting the analysis to just the first realization (r1) from each group significantly reduces the amount of data to pull."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97927ab",
   "metadata": {},
   "source": [
    "### Precip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69fc59dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Search the repository\n",
    "\n",
    "# Define query info\n",
    "query = dict(activity_id='CMIP',\n",
    "             experiment_id='historical',\n",
    "             table_id='Amon',\n",
    "             variable_id='pr',\n",
    "             member_id = 'r1i1p1f1' )\n",
    "\n",
    "# extract info for subset of models that match query\n",
    "subset = cmip6.search(require_all_on=[\"source_id\"], **query)\n",
    "\n",
    "# print verbose list of results\n",
    "#subset.df \n",
    "# print compact list of results\n",
    "subset.df.groupby(\"source_id\")[[\"experiment_id\", \"variable_id\", \"table_id\"]].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "48b8dc67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.table_id.grid_label'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='54' class='' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [54/54 00:09&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Store results in a dataset dictionary\n",
    "zarr_kwargs={'consolidated': True,\n",
    "             'decode_times': False}\n",
    "subset_dict = subset.to_dataset_dict(**zarr_kwargs) \n",
    "#list(subset_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "3ff936e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a new dictionary for manipulating\n",
    "\n",
    "# initialize\n",
    "cmip6_pr=dict()\n",
    "models_to_del=[]\n",
    "nlat_threshold=90\n",
    "\n",
    "for key in subset_dict.keys():\n",
    "    ## create shortened key name that only includes institution and source id\n",
    "    _, inst_id, src_id, _, _, _ = key.split(sep='.')\n",
    "    short_key=inst_id + '.' + src_id\n",
    "    \n",
    "    ## clean up dataset info\n",
    "    ds=subset_dict[key].pr[0] # specifying 0 uses only the first member_id\n",
    "    # make sure names of coordinate variables match\n",
    "    ds=match_lat_lon_names(ds)\n",
    "    # make a list of models with low resolution (<2.5Â°), for later\n",
    "    if np.size(ds.lat)<nlat_threshold:\n",
    "        models_to_del.append(short_key)\n",
    "    # add a source_id coordinate\n",
    "    ds=add_source_id_coord(subset_dict[key]) #ds.assign_coords(source_id=src_id)\n",
    "    \n",
    "    ## process data\n",
    "    # convert precip to mm/day\n",
    "    ds=ds*86400\n",
    "    # Trim the time range\n",
    "    #ds=ds.sel(time=slice('1948','2014'))\n",
    "    # calculate time-mean\n",
    "    ds=monthly_climatology(ds)\n",
    "    \n",
    "    ## update new dictionary with processed data\n",
    "    cmip6_pr[short_key]=ds\n",
    "\n",
    "# delete low res models\n",
    "for model in models_to_del:\n",
    "    del cmip6_pr[model]\n",
    "# also delete this one because its not on a regular grid?\n",
    "del cmip6_pr['MPI-M.ICON-ESM-LR'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "d797310a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a new dictionary for storing regridded data\n",
    "\n",
    "# initialize\n",
    "cmip6_pr_same_grid=dict()\n",
    "\n",
    "# Define standard coordinates based on lowest resolution model\n",
    "lats = cmip6_pr['NASA-GISS.GISS-E2-1-G'].lat.values\n",
    "lons = cmip6_pr['NASA-GISS.GISS-E2-1-G'].lon.values\n",
    "\n",
    "# interp model grids to lower resolution\n",
    "# all models are on a 0:360 grid so no need to convert lons\n",
    "for key,ds in cmip6_pr.items():\n",
    "    ds_lr=ds.interp(lat=lats, lon=lons)\n",
    "    ds_lr_clean=drop_all_bounds(ds_lr)\n",
    "    cmip6_pr_same_grid[key]=ds_lr_clean\n",
    "    #cmip6_pr_same_grid=xr.concat([cmip6_pr_same_grid,ds_lr], dim='source_id', coords='minimal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "c5899f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a new xarray dataset for storing regridded data\n",
    "\n",
    "# initialize\n",
    "cmip6_pr_same_grid=[]\n",
    "\n",
    "for index, (key, ds) in enumerate(cmip6_pr.items()):\n",
    "    # interp to standard grid\n",
    "    ds_lr=ds.interp(lat=lats, lon=lons)\n",
    "    ds_lr_clean=drop_all_bounds(ds_lr)\n",
    "    # concatenate\n",
    "    if index==0:\n",
    "        cmip6_pr_same_grid=ds_lr_clean\n",
    "    else:\n",
    "        cmip6_pr_same_grid=xr.concat([cmip6_pr_same_grid,ds_lr_clean], dim='source_id', coords='minimal')\n",
    "\n",
    "# clean\n",
    "cmip6_pr_same_grid=cmip6_pr_same_grid.drop(['bnds','member_id','dcpp_init_year'])\n",
    "cmip6_pr_same_grid=cmip6_pr_same_grid.drop_dims(['bnds','member_id','dcpp_init_year'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7f50b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save output\n",
    "cmip6_pr_same_grid.to_netcdf('cmip6.pr.climo.nc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a436f02b",
   "metadata": {},
   "source": [
    "### SST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3079cbeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_id</th>\n",
       "      <th>variable_id</th>\n",
       "      <th>table_id</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>source_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CESM2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CESM2-FV2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CESM2-WACCM</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CESM2-WACCM-FV2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E3SM-1-0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E3SM-1-1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>E3SM-1-1-ECA</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GFDL-CM4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GFDL-ESM4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KACE-1-0-G</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MRI-ESM2-0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 experiment_id  variable_id  table_id\n",
       "source_id                                            \n",
       "CESM2                        1            1         1\n",
       "CESM2-FV2                    1            1         1\n",
       "CESM2-WACCM                  1            1         1\n",
       "CESM2-WACCM-FV2              1            1         1\n",
       "E3SM-1-0                     1            1         1\n",
       "E3SM-1-1                     1            1         1\n",
       "E3SM-1-1-ECA                 1            1         1\n",
       "GFDL-CM4                     1            1         1\n",
       "GFDL-ESM4                    1            1         1\n",
       "KACE-1-0-G                   1            1         1\n",
       "MRI-ESM2-0                   1            1         1"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Search the repository\n",
    "\n",
    "# Define query info\n",
    "# only want to use simulations with a rectified grid since ocean grids are weird\n",
    "query = dict(activity_id='CMIP',\n",
    "             experiment_id='historical',\n",
    "             table_id='Omon',\n",
    "             variable_id='tos',\n",
    "             grid_label='gr',\n",
    "             member_id = 'r1i1p1f1' )\n",
    "\n",
    "# extract info for subset of models that match query\n",
    "subset = cmip6.search(require_all_on=[\"source_id\"], **query)\n",
    "\n",
    "# print verbose list of results\n",
    "#subset.df \n",
    "# print compact list of results\n",
    "subset.df.groupby(\"source_id\")[[\"experiment_id\", \"variable_id\", \"table_id\"]].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d7d2f149",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--> The keys in the returned dictionary of datasets are constructed as follows:\n",
      "\t'activity_id.institution_id.source_id.experiment_id.table_id.grid_label'\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      <progress value='11' class='' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      100.00% [11/11 00:09&lt;00:00]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## Store results in a dataset dictionary\n",
    "zarr_kwargs={'consolidated': True,\n",
    "             'decode_times': False}\n",
    "subset_dict = subset.to_dataset_dict(**zarr_kwargs) \n",
    "#list(subset_dict.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4f603c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a new dictionary for manipulating\n",
    "\n",
    "# initialize\n",
    "cmip6_sst=dict()\n",
    "models_to_del=[]\n",
    "nlat_threshold=90\n",
    "\n",
    "for key in subset_dict.keys():\n",
    "    ## create shortened key name that only includes institution and source id\n",
    "    _, inst_id, src_id, _, _, _ = key.split(sep='.')\n",
    "    short_key=inst_id + '.' + src_id\n",
    "    \n",
    "    ## clean up dataset info\n",
    "    ds=subset_dict[key].tos[0] # specifying 0 uses only the first member_id\n",
    "    # make sure names of coordinate variables match\n",
    "    ds=match_lat_lon_names(ds)\n",
    "    # make a list of models with low resolution (<2.5Â°), for later\n",
    "    if np.size(ds.lat)<nlat_threshold:\n",
    "        models_to_del.append(short_key)\n",
    "    # add a source_id coordinate\n",
    "    ds=add_source_id_coord(subset_dict[key]) #ds.assign_coords(source_id=src_id)\n",
    "    \n",
    "    ## process data\n",
    "    # Trim the time range\n",
    "    #ds=ds.sel(time=slice('1948','2014'))\n",
    "    # calculate monthly climatologies\n",
    "    ds=monthly_climatology(ds)\n",
    "    \n",
    "    ## update new dictionary with processed data\n",
    "    cmip6_sst[short_key]=ds\n",
    "\n",
    "# delete low res models\n",
    "for model in models_to_del:\n",
    "    del cmip6_sst[model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7a412217",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a new dictionary for storing regridded data\n",
    "\n",
    "# initialize\n",
    "cmip6_sst_same_grid=dict()\n",
    "\n",
    "# Use coordinates from a standard 1Â°x1Â° ocean model\n",
    "lats = cmip6_sst['E3SM-Project.E3SM-1-0'].lat.values\n",
    "lons = cmip6_sst['E3SM-Project.E3SM-1-0'].lon.values\n",
    "\n",
    "# interp model grids to lower resolution\n",
    "# all models are on a 0:360 grid so no need to convert lons\n",
    "for key,ds in cmip6_sst.items():\n",
    "    ds_lr=ds.interp(lat=lats, lon=lons)\n",
    "    ds_lr_clean=drop_all_bounds(ds_lr)\n",
    "    cmip6_sst_same_grid[key]=ds_lr_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "33ab1ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create a new xarray dataset for storing regridded data\n",
    "\n",
    "# Use coordinates from a standard 1Â°x1Â° ocean model\n",
    "lats = cmip6_sst['E3SM-Project.E3SM-1-0'].lat.values\n",
    "lons = cmip6_sst['E3SM-Project.E3SM-1-0'].lon.values\n",
    "\n",
    "# initialize\n",
    "cmip6_sst_same_grid=[]\n",
    "\n",
    "for index, (key, ds) in enumerate(cmip6_sst.items()):\n",
    "    # interp to standard grid\n",
    "    ds_lr=ds.interp(lat=lats, lon=lons)\n",
    "    ds_lr_clean=drop_all_bounds(ds_lr)\n",
    "    ds_lr_clean=ds_lr_clean.squeeze()\n",
    "    # concatenate\n",
    "    if index==0:\n",
    "        cmip6_sst_same_grid=ds_lr_clean\n",
    "    else:\n",
    "        cmip6_sst_same_grid=xr.concat([cmip6_sst_same_grid,ds_lr_clean], dim='source_id', coords='minimal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8d1303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save output\n",
    "cmip6_sst_same_grid.to_netcdf('cmip6.sst.climo.nc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pangeo)",
   "language": "python",
   "name": "pangeo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
